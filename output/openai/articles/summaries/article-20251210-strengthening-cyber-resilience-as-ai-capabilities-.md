---
title: "Strengthening cyber resilience as AI capabilities advance"
published: "2025-12-10"
url: "https://openai.com/index/strengthening-cyber-resilience"
source: "news"
source_medium: "OpenAI News"
language: "ja"
---

# Strengthening cyber resilience as AI capabilities advance


## Summary
AIモデルのサイバーセキュリティ能力が急速に進化しており、防御側にとって大きな利益をもたらす一方で、悪用される潜在的なリスクも増大しています。例えば、CTF（Capture-The-Flag）チャレンジにおけるモデルの能力は、2025年8月のGPT-5の27%から、2025年11月にはGPT-5.1-Codex-Maxで76%へと向上しました。OpenAIは、将来のAIモデルが「Preparedness Framework」で定義される「High」レベルのサイバーセキュリティ能力に達する可能性に備え、防御側がコードの監査や脆弱性パッチ適用といった作業をより効率的に行えるよう、モデルとツールの強化に投資しています。

このような能力の進展に伴い、OpenAIはデュアルユース（善用と悪用の両方に使用できる）のリスクを慎重に管理するため、多層的な安全対策を講じています。これには、有害なリクエストを拒否するようにモデルをトレーニングすること、悪意のある活動を検出するシステムを導入すること、そして専門家によるエンドツーエンドのレッドチーム演習を実施して防御を継続的に強化することが含まれます。

さらに、OpenAIはサイバーレジリエンスを強化するためのエコシステム全体の取り組みも推進しています。これには、サイバー防御に取り組む資格のあるユーザーに最新モデルの強化された機能への階層的なアクセスを提供する「信頼できるアクセスプログラム」、脆弱性の発見と修正を支援するエージェント型セキュリティ研究者「Aardvark」の提供、サイバー防御専門家と連携する「Frontier Risk Council」の設立、そしてFrontier Model Forumを通じて業界全体で脅威モデルとベストプラクティスに関する共通理解を深める努力が含まれます。これらの取り組みを通じて、AIの能力が防御側に最大限活用され、現実世界のセキュリティが効果的に向上することを目指しています。

## Key Points
- AIモデルのサイバーセキュリティ能力は急速に向上しており、GPT-5.1-Codex-Maxは2025年11月にCTF課題で76%の性能を達成しました。
- OpenAIは、AIモデルが悪用されるリスクを軽減するため、アクセス制御、インフラ強化、監視、検知・対応システムを含む多層的な安全対策を実施しています。
- 有害なリクエストを拒否し、悪意のある活動を検出するようモデルをトレーニングし、エンドツーエンドのレッドチーム演習で防御を強化しています。
- サイバー防御を目的とした「信頼できるアクセスプログラム」の導入や、脆弱性発見・修正を支援する「Aardvark」のプライベートベータ版を提供しています。
- サイバー防御専門家との協力グループ「Frontier Risk Council」を設立し、業界と連携して脅威モデルの共通理解を深めることで、エコシステム全体のサイバーレジリエンス強化を目指しています。