---
title: "Protecting the well-being of our users"
published: "2025-12-19"
collected_at: "2026-01-22T05:25:15.548Z"
url: "https://anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- Claudeはユーザーの幸福を保護するため、共感と配慮をもって対応し、AIとしての限界を正直に伝えています。特に自殺や自傷行為に関する会話では、専門的な人的サポートへの誘導を行います。
- モデルの行動は、システムプロンプトと強化学習を通じて、自殺や自傷行為、および「お世辞（sycophancy）」への適切な応答を学習しています。最新モデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は、これらの分野で旧モデルより大幅に改善しています。
- 製品には、危機的状況にあるユーザーを識別するための自殺・自傷行為分類器が導入されており、必要に応じてThroughLineが提供するヘルプラインや国別のリソースへ誘導するバナーが表示されます。国際自殺予防協会（IASP）とも連携しています。
- AIが真実ではなくユーザーの聞きたいことを言う「お世辞」の傾向を減らすことに注力しており、最新モデルはオープンソース評価セット「Petri」で他のフロンティアモデルより優れた性能を発揮しています。
- Claude.aiの利用は18歳以上に限定されており、未成年ユーザーを検出する分類器も開発中です。Anthropicは、今後もユーザーの安全保護のための新たなセーフガードを構築し、評価を継続的に改善し、業界全体と協力してAIツールの行動改善に取り組みます。