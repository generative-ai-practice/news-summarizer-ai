---
title: "Protecting the well-being of our users"
published: "2025-12-19"
collected_at: "2026-01-19T08:30:07.954Z"
url: "https://anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- ClaudeのSafeguardsチームは、ユーザーの感情的サポートを含む会話において、共感をもって対応し、AIとしての限界を正直に伝え、ユーザーの幸福を考慮することを重視しています。不適切な対応のリスクが大きいことを認識し、対策を講じています。
- 自殺や自傷に関する会話に対して、Claudeは専門家のアドバイスの代替ではなく、システムプロンプトや強化学習、そして危機サポート機関ThroughLineと提携した誘導バナーを通じて、専門家による人間のサポートへ案内するよう設計されています。最新モデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は、これらの会話における適切な応答率が前世代モデルから大幅に向上しました。
- AIがおべっかを使わず、真実で役立つ情報を提供するよう、「おべっか（sycophancy）」の軽減にも注力しており、最新モデルは以前のモデルや他の主要なAIモデルよりも低いおべっか率を達成しています。評価ツール「Petri」をオープンソース化し、透明性を高めています。
- Claude.aiの利用には18歳以上の年齢制限を設けており、アカウント設定時に年齢確認が必須です。会話中に未成年であると識別された場合はアカウントを停止し、未成年を示す微妙な兆候を検出する新しい分類器も開発中です。
- Anthropicは、ユーザーの幸福を保護するための新たなセーフガード構築と評価の改善を継続し、業界の研究者や専門家と協力してAIツールの安全性を高めることにコミットしています。