---
title: "Protecting the well-being of our users"
published: "2025-12-19"
url: "https://www.anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- Anthropicはユーザーの幸福保護を重視し、AIが感情的サポートを適切に行い、AIの限界を正直に伝え、共感をもって対応するよう努めている。
- 自殺や自傷に関する会話に対し、Claudeは専門家の助言の代替ではないことを明確にしつつ、モデルトレーニングと危機サポート（ThroughLine提携のヘルプラインなど）への誘導バナーを通じて、共感的かつ慎重に対応する。
- 最新のClaudeモデル（Opus 4.5、Sonnet 4.5、Haiku 4.5）は、自殺や自傷に関する単一ターンで98.6%〜99.3%、複数ターン会話で86%〜78%の適切な応答率を達成し、旧モデルからの大幅な改善を示した。
- AIの「追従性」（ユーザーの望むことを言う傾向）を低減する取り組みを進めており、最新モデルは自動行動監査およびオープンソースのPetri評価セットで顕著な改善を達成している。
- Claude.aiは18歳以上の利用を義務付けており、未成年者の利用を特定してアカウントを無効化する製品セーフガードを導入し、Family Online Safety Institute (FOSI) と連携してこの分野の取り組みを強化している。