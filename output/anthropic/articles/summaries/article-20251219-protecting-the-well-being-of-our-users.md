---
title: "Protecting the well-being of our users"
published: "2025-12-19"
url: "https://www.anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users


## Summary
Anthropicは、AIがユーザーの精神的な健康に配慮した対話を行うための取り組みについて詳述しています。特に、自殺や自傷行為に関する会話において、Claudeが共感的に応答し、AIとしての限界を正直に伝え、必要に応じてヘルプラインやメンタルヘルス専門家などの人間によるサポートへとユーザーを導くことを目指しています。これらの対話で適切なセーフガードがない場合のリスクは非常に大きいと認識されています。

具体的な対策として、システムプロンプトや強化学習によるモデルトレーニングに加え、Claude.ai上での製品レベルのセーフガードを導入しています。これには、自殺や自傷行為の可能性のある会話を検出する分類器と、それに応じてCrisis Text Lineや日本のいのちの電話などの国別リソースへ誘導するバナー表示が含まれます。Anthropicは、これらの取り組みについてThroughLineや国際自殺予防協会（IASP）と協力し、ベストプラクティスを製品に反映させています。

モデルの挙動評価では、単一のメッセージ応答、複数ターンの会話、および過去の実際の会話を用いたストレステストを通じてClaudeの性能を検証しています。最新モデルであるClaude Opus 4.5、Sonnet 4.5、およびHaiku 4.5は、自殺や自傷行為に関する適切な応答率が向上し、ユーザーに迎合する「追従性（sycophancy）」も大幅に軽減されていることが示されています。また、18歳未満のユーザーによる製品利用を制限し、年齢確認の強化と未成年者検出のための新たな分類器の開発に取り組んでいます。

## Key Points
- Claudeは、ユーザーの精神的健康を守るため、自殺や自傷行為に関する会話に共感的に対応し、専門家やサポート機関へ適切に誘導する方針を掲げている。
- モデルのトレーニング（システムプロンプト、強化学習）と製品レベルのセーフガード（自殺・自傷行為分類器、各国対応のヘルプラインへのバナー誘導）を導入。
- 最新モデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は、自殺・自傷行為に対する適切な応答率が向上し、ユーザーに迎合する「追従性（sycophancy）」が大幅に軽減されたことを複数の評価で確認。
- 特に、オープンソースのPetri評価セットにおいて、Anthropicの4.5モデルファミリーは他の主要モデルよりも優れた追従性軽減効果を示している。
- 18歳以上のユーザーのみがClaude.aiを利用でき、アカウント設定時の年齢確認のほか、未成年者を検出する新たな分類器の開発を進めている。

---

*Generated by Provider News Monitor using Gemini 2.5 Flash*