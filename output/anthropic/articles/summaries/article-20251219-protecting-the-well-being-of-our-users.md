---
title: "Protecting the well-being of our users"
published: "2025-12-19"
url: "https://anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- Claudeはユーザーの幸福を最優先し、共感、AIとしての限界への正直さ、ユーザーの状況への配慮を重視するセーフガードを導入しています。これは、自殺・自傷行為に関する会話や、ユーザーの意見に盲目的に同意する「追従性」の低減に焦点を当てています。
- 自殺や自傷行為の兆候が見られる会話では、Claudeは専門家によるサポート（ヘルプライン、精神保健専門家など）に誘導するよう訓練されており、危機バナー表示機能やThroughLine、国際自殺予防協会(IASP)との連携を通じて、日本のLife Linkを含む国別のリソースも提供しています。
- 最新モデル（Claude Opus 4.5, Sonnet 4.5, Haiku 4.5）は、自殺・自傷行為に関する単一および複数ターン会話において、適切な応答率が98.6%から99.3%に向上し、以前のモデル（Opus 4.1の56%）と比較して複数ターン会話での適切応答率も大幅に改善（Opus 4.5で86%、Sonnet 4.5で78%）しました。
- モデルの「追従性」を評価・低減する取り組みにより、最新モデルは自動行動監査においてOpus 4.1よりも70-85%低いスコアを記録し、オープンソース評価セット「Petri」でも他の主要なフロンティアモデルよりも優れた性能を示しています。
- 未成年ユーザーへの悪影響リスクを鑑み、Claude.aiは18歳以上を対象としており、アカウント設定時の年齢確認や、未成年と確認されたアカウントの無効化、未成年を検出する新しい分類器の開発に取り組んでいます。