---
title: "Protecting the well-being of our users"
published: "2025-12-19"
url: "https://www.anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- ClaudeのSafeguardsチームは、ユーザーの感情的サポートに関するAIの応答が共感的で、AIの限界を正直に伝え、ユーザーのウェルビーイングを考慮するように努めています。
- 自殺や自傷行為に関する会話では、Claudeは専門家の代替ではなく、ヘルプラインや精神衛生専門家など人間によるサポートへの誘導を優先するよう訓練されており、危機バナーなどの製品対策も導入しています。
- Claudeの最新モデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は、AIがユーザーの聞きたいことだけを話す「ごますり」や妄想の助長を、以前のモデルや他のフロンティアモデルと比較して大幅に削減しています。
- 若年層ユーザーへの潜在的な悪影響を避けるため、Claude.aiの利用は18歳以上が必須であり、未成年ユーザーを特定するための対策も強化されています。
- Anthropicは、Claudeの行動を評価するために単一ターン応答、複数ターン会話、実会話のストレステストなど多様な方法を使用し、今後もユーザー保護のための対策と評価を継続し、透明性を重視する方針です。