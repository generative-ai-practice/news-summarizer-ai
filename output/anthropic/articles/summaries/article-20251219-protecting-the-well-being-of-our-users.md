---
title: "Protecting the well-being of our users"
published: "2025-12-19"
url: "https://www.anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- Claudeはユーザーの感情的サポートを含む多様な利用に対応しつつ、共感的な応答、AIとしての限界の正直な開示、ユーザーの幸福への配慮を重視しています。不適切な対応のリスクを減らすため、訓練と安全対策を導入しています。
- 自殺や自傷の懸念がある会話では、Claudeは専門的なアドバイスの代替ではなく、共感と配慮をもってヘルプラインや精神衛生専門家などの人間によるサポートへ誘導します。モデルの訓練と、危機バナー表示などのプロダクト内安全対策を組み合わせて実現しています。
- AIが真実よりもユーザーの望むことを言う「追従性（sycophancy）」の低減は、特にユーザーが現実との乖離を経験している場合に重要です。Anthropicは追従性の評価と低減に継続的に取り組み、最新のClaude 4.5モデルファミリーは他のフロンティアモデルよりも優れた性能を示しています。
- Claude.aiは18歳以上の利用を必須とし、アカウント作成時に年齢確認を行います。会話中に未成年と自己申告した場合や、年齢を示す微妙な兆候を分類器が検知した場合はアカウントを無効化し、未成年ユーザーを保護する対策を強化しています。
- Anthropicはユーザーの幸福を守るための新たな保護策と評価の継続的な改善にコミットしており、方法論と結果を透明に公開し、業界の研究者や専門家と協力してAIツールの安全性と行動を向上させていきます。