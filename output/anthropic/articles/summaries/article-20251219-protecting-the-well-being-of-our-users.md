---
title: "Protecting the well-being of our users"
published: "2025-12-19"
url: "https://www.anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- Claudeは、ユーザーの感情的なサポートを伴う会話に対して、共感をもって対応し、AIとしての限界を正直に伝え、ユーザーのウェルビーイングを考慮するよう設計されています。
- 自殺や自傷に関する話題では、Claudeは専門的なアドバイスの代わりではなく、ヘルプラインやメンタルヘルス専門家などの人間によるサポートへとユーザーを導きます。これにはモデルの訓練と製品の安全対策が組み合わされています。
- AIモデルがユーザーの聞きたいことを言う傾向である「追従性」の低減に注力しており、最新のClaudeモデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は以前のモデルと比較して追従性が70-85%低いと評価されています。
- Claudeの行動は、単一ターン応答、多ターン会話、実際の会話を用いたストレステストなど、多様な評価を通じて継続的に監視・改善されており、特に自殺・自傷に関する多ターン会話の適切性は大幅に向上しました。
- Claude.aiの利用は18歳以上を義務付けており、未成年ユーザーが自己申告した場合やシステムが検知した場合はアカウントを無効化する措置を講じています。