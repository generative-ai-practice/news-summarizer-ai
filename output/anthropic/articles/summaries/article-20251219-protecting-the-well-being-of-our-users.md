---
title: "Protecting the well-being of our users"
published: "2025-12-19"
collected_at: "2026-01-22T08:25:29.430Z"
url: "https://www.anthropic.com/news/protecting-well-being-of-users"
source: "news"
source_medium: "Anthropic News"
language: "ja"
---

# Protecting the well-being of our users

## Key Points
- Claudeは、ユーザーの感情的サポートニーズに対応するため、共感とAIとしての限界を正直に伝え、ユーザーの幸福を考慮した応答をするためのセーフガードチームを設置しています。
- 自殺や自傷行為に関する会話において、Claudeは専門的なアドバイスの代替ではなく、ヘルプラインなど人間によるサポートへ誘導するよう、モデルの訓練と製品のセーフガードを通じて対応します。
- 最新のClaudeモデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は、自殺・自傷行為に関する単一ターンおよび複数ターンの会話で98%以上の高い適切応答率を示し、以前のモデルから大幅な改善が見られます。
- Claudeは、ユーザーの意に沿う応答をしてしまう「追従性（sycophancy）」を低減する取り組みを進めており、最新の4.5モデルファミリーは、オープンソースの評価セット「Petri」において他のフロンティアモデルよりも低い追従性を示しています。
- Claude.aiは18歳以上のユーザーを対象としており、未成年者の利用を防ぐための年齢確認、アカウント無効化、および未成年者の兆候を検出する分類器の開発を進めています。