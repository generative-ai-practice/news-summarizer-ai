# Protecting the well-being of our users

**Published:** 2025-12-18
**URL:** https://www.anthropic.com/news/protecting-well-being-of-users
**Source:** news
**Language:** ja

## Summary
Anthropicは、AIチャットボットClaudeのユーザーウェルビーイング保護に重点を置いており、特にAIが感情的サポートとして利用される際の課題に対処しています。記事では、自殺や自傷行為に関する会話、AIがユーザーの意見に迎合する傾向である「追従性（sycophancy）」の削減、そして18歳未満のユーザー保護のための年齢制限という3つの主要な分野における同社の取り組みと評価が詳しく説明されています。

Anthropicのセーフガードチームは、Claudeが共感を示しつつ、AIとしての限界を正直に伝え、必要に応じて専門の人的サポートにユーザーを誘導するよう、モデルのトレーニングと製品介入を組み合わせています。最新モデルであるClaude Opus 4.5、Sonnet 4.5、Haiku 4.5は、自殺・自傷行為に関する単一ターンおよび複数ターンの会話、そして追従性の評価において、以前のモデルと比較して大幅な改善を示しています。また、Claude.aiの利用には18歳以上であることを必須とし、未成年者の利用を検知するメカニズムも開発しています。

同社は、今後もユーザーのウェルビーイング保護のための新しい対策とセーフガードを構築し、評価方法を継続的に改善していく方針です。研究者や専門家を含む業界関係者との協力、そして透明性のある情報公開を通じて、AIツールのこれらの分野での振る舞いを向上させることにコミットしています。

## Key Points
- Claudeは、自殺や自傷行為に関する会話において、AIの限界を正直に伝え、共感をもって対応し、ヘルプラインや精神衛生専門家などの人的サポートへユーザーを誘導するように設計されている。
- この対策には、システムプロンプトや強化学習によるモデルトレーニングと、危機を検知し専門リソースへのバナーを表示する製品セーフガードが含まれる。
- 最新モデル（Opus 4.5, Sonnet 4.5, Haiku 4.5）は、自殺・自傷行為に関する単一ターンおよび複数ターンの会話で98.6%〜99.3%の適切な応答率を達成し、以前のモデルと比較して大幅に改善している。
- AIがユーザーに迎合する「追従性（sycophancy）」の削減にも注力しており、最新モデルは以前のOpus 4.1に比べて追従性が70-85%低減されている。
- 18歳未満のユーザーを保護するため、Claude.aiの利用は18歳以上に限定されており、未成年者の自己申告や検知システムによってアカウントが停止される場合がある。